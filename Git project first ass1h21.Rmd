---
title: "Can R Notebooks help with reproducibility?"
output:
  pdf_document: default
  html_document:
    df_print: paged
bibliography: references.bib
---

# Introduction

## Reproducibility

**In this paper we will discuss the differences between replicability and reproducibility, the importance of reproducibility in science and how R Notebook may be a potential solution to this problem.**


Scientific research and the methodologies have undergone tremendous technological evolutions in the latest decades. However, the manner these scientific papers and studies are being published have stayed in the most part the same, and to an extent we can say that its fifty years behind [@gentleman2005]. For instance, we find that many scientific papers that have been published, are in later days being falsely concluded when thoroughly replicated. One such example can be illustrated with Giles and Tedds (2002) book about the Canadian underground economy. Their founding's showed that the illegal economy had grown tremendously in just under two decades from 3.6% to 15,6 % [@mccullough2008] However, the model they used, MIMIC (multiple indicator, multiple cause), was in later years deemed useless by researcher Breusch (2005) for this experiment.

## Challenges

Science advances on findings of trustworthy research and results. A crucial factor in knowing whether these findings are reliable is whether it is possible to reproduce the results. The ability to reproduce a research and get the same results is essential when making trusted conclusion. Unfortunately reproducibility is one big challenge in science. Many articles that are produced in peer-reviewed journals have problems with reproducibility [@mcnutt2014]. These challenges entails weak ability of investigators to build on prior work. The problems with reproducibility arise due to deficient of data and documentation of used procedures, software and packages. A reason to why this deficiency occur is old, lost or unpublished data. Data, software and packages are in many cases kept private, which makes it impossible to duplicate the original research.

What we try to understate here is that even though scientific development has seen huge growth, especially in the 20th century, there is much information being produced that are misleading. As a consequence, new methods have to be implemented to set a basis standard for scientific claims. Not only to validate these claims, but also to reduce the uncertainty and dangers for other scientists to become involved in a study with money and resources that are later shown to be false. [@peng2011] suggests in the beginning of his article about reproducible research, that reproducibility in fact, should become a minimum requirement for scientific papers to validate their claims.

# Short literature review

Replication of a study is seen as Jesny et al. (2011) suggests as the "gold standard" in scientific research. We can define replication as *"the ability of a researcher to duplicate the result of a prior study if the same procedures are followed, but new data are collected"* [@bollen2015]. One reason why it's considered the absolute gold standard for researcher is that they can conduct the experiment or study in a new way, with new data-sets, but still conclude the same result. Reproducibility on the other hand can be seen as *"the ability of a researcher to duplicate the results of a prior study using the same materials and procedures as were used by the original investigator"* @bollen2015. Here the same procedures and data will be used to attempt to attain the same result as the original investigation. From the definitions we can see that replication is much wider than reproducibility, giving room for more flexibility in the research.

In economics, there have been different leading professional journals published by scientists. In 1933, Frisch composed a journal that worked as a leading article in econometrics for many years. During this period, scientists would not publish original data in statistical and numerous work unless their volume were excessive or comprehensive @frisch1933.

In Frisch's journal, Ezekiel wrote an empirical work with conducting datasets. In this era, regression analysis was pervasive to implement even though the datasets were available [@ezekiel1933].

In 1960, scientists advanced big economic models. However, notwithstanding bigger models, it was still unmanageable to move data from one mainframe to another. The predicaments arose because scientists produced the datasets in software and programs related to specific computers. The research results were published exclusively, without exposure of codes, datasets, or research procedures. This way of constructing made reproduction nearly impossible.

The leading professional journal, "The journal of money, credit and banking project", founded by Dewald in 1982, attempted to replicate published articles. The investigators conducted a study on the reproducibility of published articles by using datasets submitted with various published articles. This attempt concluded that only 2 of the 70 examined articles were possible to reproduce [@dewald1986]. The results were generally disappointing due to missing data, software errors, no documentation, lost and missing investigators and data. In addition, many authors just ignored requests for data and code.

# Discussion

When performing research in R notebooks all codes used trough the performance is saved and documented. Accordingly, R notebooks helps reduce a barrier to reproducibility by making codes available. Published and available codes give other researchers and scientist the ability to follow the same procedures when duplicating research. For instance the function *"SessionInfo"* can be helpful and informative when duplicating procedures as it documents information about which packages and R versions used by the original investigator.

***This is an example of a code-chunk which shows the packages used in the program.***

```{r Example SessionInfo Code-Chunk}
sessionInfo()
```

R Notebooks can be aligned with reproducibility as it enables documentation of used procedures. In this way potential mistakes in the procedure can be reveald. However, this is only the case if the scientis saves the versions of tools being used and results are interpreted in the R notebook. @peng2011 emphasizes that even though a research is reproducible, quality, correctness and validity of the published results is not guaranteed.

## A potential solution

A potential solution to this issue is the implementation of a research compendium, which combines text, data and auxiliary software. [@gentleman2007] described a compendium as "a container for the different elements that make up the document and its computations, and as a means for distributing, managing and updating the collection". The goal here is to achieve a greater way to construct a reproducible project with software such as R. An important factor to the compendium is that it contains

# Conclusion

Help but not a solution/fix Issues such as: Different OS system, packages, software etc


# **References**

::: {#refs}
:::

# Appendix

1.  Screenshot of git-history

-   We have included a screenshot of our git-history to show commits and branches used during writing this paper.

![](images/Skjermbilde%202021-09-16%20kl.%2011.44.39.png)
