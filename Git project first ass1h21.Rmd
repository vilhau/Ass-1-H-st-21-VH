---
title: "Can R Notebooks help with reproducibility?"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Introduction

## Reproducibility

In this paper we will discuss the differences between replicability and reproducibility, the importance of reproducibility in science and how R Notebook may be a potential solution to this problem.

Scientific research and the methodologies have undergone tremendous technological evolutions in the latest decades. However, the manner these scientific papers and studies are being published have stayed in the most part the same, and to an extent we can say that its fifty years behind (Gentleman, 2005). For instance, we find that many scientific papers that have been published, are in later days being falsely concluded when thoroughly replicated. One such example can be illustrated with Giles and Tedds (2002) book about the Canadian underground economy. Their founding's showed that the illegal economy had grown tremendously in just under two decades from 3.6% to 15,6 % (McCullough et al., 2008) However, the model they used, MIMIC (multiple indicator, multiple cause), was in later years deemed useless by researcher Breusch (2005) for this experiment.

Dette er bare tull for å få noe nytt i en branch. sbhjhgjashjgkdghj ahjhjhj hjadhjadhjks

snmsmbdmnmnskjhkashjks

asnhashjashj jkjhshjkhkjads USAHKUHKJKHJ

## Challenges

Science advances on findings of trustworthy research and results. A crucial factor in knowing whether these findings are reliable is whether it is possible to reproduce the results. The ability to reproduce a research and get the same results is essential when making trusted conclusion. Unfortunately reproducibility is one big challenge in science. Many articles that are produced in peer-reviewed journals have problems with reproducibility (McNutt 2014). These challenges entails weak ability of investigators to build on prior work. The problems with reproducibility arise due to deficient of data and documentation of used procedures, software and packages. A reason to why this deficiency occur is old, lost or unpublished data. Data, software and packages are in many cases kept private, which makes it impossible to duplicate the original research.

What we try to understate here is that even though scientific development has seen huge growth, especially in the 20th century, there is much information being produced that are misleading. As a consequence, new methods have to be implemented to set a basis standard for scientific claims. Not only to validate these claims, but also to reduce the uncertainty and dangers for other scientists to become involved in a study with money and resources that are later shown to be false. Peng (2011) suggests in the beginning of his article about reproducible research, that reproducibility in fact, should become a minimum requirement for scientific papers to validate their claims.

# Short literature review

Replication of a study is seen as Jesny et al. (2011) suggests as the "gold standard" in scientific research. We can define replication as *"the ability of a researcher to duplicate the result of a prior study if the same procedures are followed, but new data are collected"* (Bollen. Et al., 2015, p. 7). One reason why it's considered the absolute gold standard for researcher is that they can conduct the experiment or study in a new way, with new data-sets, but still conclude the same result. Reproducibility on the other hand can be seen as *"the ability of a researcher to duplicate the results of a prior study using the same materials and procedures as were used by the original investigator"* (Bollen et al., 2015, p. 6). Here the same procedures and data will be used to attempt to attain the same result as the original investigation. From the definitions we can see that replication is much wider than reproducibility, giving room for more flexibility in the research.

Se på foredraget: 1930

# Discussion

When performing research in R notebooks all codes used trough the performance is saved and documented. Accordingly, R notebooks helps reduce a barrier to reproducibility by making codes available. Published and available codes give other researchers and scientis the ability to follow the same procedures when duplicating research. For instance the function *"SessionInfo"* can be helpful and informative when duplicating procedures as it documents information about which packages and R versions used by the original investigator.

```{r Example SessionInfo Code-Chunk}
sessionInfo()
```

R Notebooks can be aligned with reproducibility as it enables documentation of used procedures. In this way potential mistakes in the procedure can be reveald. However, this is only the case if the scientis saves the versions of tools being used and results are interpreted in the R notebook. Peng (2011) emphasizes that even though a research is reproducible, quality, correctness and validity of the published results is not guaranteed.

## A potential solution

A potential solution to this issue is the implementation of a research compendium, which combines text, data and auxiliary software. Gentleman and Lang (2004, p. 1) described a compendium as "a container for the different elements that make up the document and its computations, and as a means for distributing, managing and updating the collection". The goal here is to achieve a greater way to construct a reproducible project with software such as R. An important factor to the compendium is that it contains

# Conclusion

Help but not a solution/fix Issues such as: Different OS system, packages, software etc

# **References**

McCullough, B. D., McGeary, K. A., & Harrison, T. D. (2008). Do economics journal archives promote replicable research?. Canadian Journal of Economics/Revue canadienne d'économique, 41(4), 1406-1420.

Bollen, K., Cacioppo, J. T., Kaplan, R. M., Krosnick, J. A., & Olds, J. L. (2015). Reproducibility, replicability, and generalization in the social, behavioral, and economic sciences. *Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences. Arlington, VA: National Science Foundation*.
